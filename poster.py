# -*- coding: utf-8 -*-
"""poster.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q9wh7fVXeY_Z8HbOSn7Fs8-JWK0R_W44
"""

pip install pandas numpy scikit-learn matplotlib seaborn

pip install tensorflow

from google.colab import files
uploaded = files.upload()  # Choose ecg_sleep_apnea_dataset.csv when prompted

import pandas as pd
df = pd.read_csv('ecg_sleep_apnea_dataset.csv')
df.head()

from google.colab import files
uploaded = files.upload()  # Upload your ecg_sleep_apnea_dataset.csv.zip

import zipfile
import os

# Extract zip file
with zipfile.ZipFile("ecg_sleep_apnea_dataset.csv.zip", 'r') as zip_ref:
    zip_ref.extractall(".")

# Now check what files were extracted
print(os.listdir("."))

import pandas as pd

df = pd.read_csv("ecg_sleep_apnea_dataset.csv")
df.head()

print(df.info())
print(df.isnull().sum())

df = df.dropna()  # or use df.fillna(method='ffill')

X = df.drop(['Target'], axis=1)
y = df['Target']

# Features and labels
X = df.drop(['Target'], axis=1)
y = df['Target']

# Convert target to integer by mapping string labels to numerical values
y = y.map({'Normal': 0, 'Sleep Apnea': 1})

print(df.columns.tolist())

# Apply feature engineering to all numerical columns
# Drop the 'Target' column from df before applying rolling window functions
df_processed = df.drop(['Target'], axis=1)

for col in df_processed.columns:
    df[f'{col}_mean'] = df_processed[col].rolling(window=100).mean()
    df[f'{col}_std'] = df_processed[col].rolling(window=100).std()
    df[f'{col}_rms'] = (df_processed[col]**2).rolling(window=100).mean()**0.5

# Drop original columns and rows with NaN values created by rolling window
# Keep the original 'Target' column from the original df
original_target = df['Target']
df = df.drop(df_processed.columns, axis=1)

# Combine the processed features with the original target column
df = pd.concat([df, original_target], axis=1)

df = df.dropna()

# Update X and y after feature engineering and dropping NaNs
X = df.drop(['Target'], axis=1)
y = df['Target']

from sklearn.model_selection import train_test_split

X = df.drop(['Target'], axis=1)
y = df['Target']

# Convert target to integer by mapping string labels to numerical values
y = y.map({'Normal': 0, 'Sleep Apnea': 1})


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

from sklearn.preprocessing import StandardScaler

# Ensure target is integer
y_train = y_train.astype('int')
y_test = y_test.astype('int')

# Normalize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Deep Learning model
from tensorflow.keras import layers, models

model = models.Sequential([
    layers.Input(shape=(X_train_scaled.shape[1],)),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(64, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)

loss, accuracy = model.evaluate(X_test_scaled, y_test)
print(f"Test accuracy: {accuracy:.2f}")

# For ML
import joblib
joblib.dump(model, 'apnea_rf_model.pkl')

# For Deep Learning
model.save('apnea_nn_model.h5')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Optional: make plots pretty
sns.set(style="whitegrid")

print(type(df))
print(df.head())

df = pd.read_csv('ecg_sleep_apnea_dataset.csv')  # Or your correct path

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(x='Target', data=df)
plt.title('Class Distribution')
plt.xticks([0, 1], ['Normal', 'Apnea'])
plt.ylabel('Count')
plt.xlabel('Condition')
plt.show()

# Pick a random row and drop the 'Target'
sample_index = np.random.randint(0, len(df))
ecg_signal = df.drop('Target', axis=1).iloc[sample_index].astype(float)

plt.plot(ecg_signal.values)
plt.title(f"ECG Sample #{sample_index} (Label = {df['Target'].iloc[sample_index]})")
plt.xlabel('Time Step')
plt.ylabel('Amplitude')
plt.grid(True)
plt.show()

# Convert all signal values to float
normal = df[df['Target'] == 0].drop('Target', axis=1).astype(float)
apnea = df[df['Target'] == 1].drop('Target', axis=1).astype(float)

mean_normal = normal.mean()
mean_apnea = apnea.mean()

plt.figure(figsize=(12, 5))
plt.plot(mean_normal.values, label='Normal', alpha=0.8)
plt.plot(mean_apnea.values, label='Apnea', alpha=0.8)
plt.title('Average ECG Signal - Normal vs Apnea')
plt.xlabel('Time Step')
plt.ylabel('Mean Amplitude')
plt.legend()
plt.grid(True)
plt.show()

subset = df.iloc[:, :20]  # Use first 20 ECG features to avoid memory issues
plt.figure(figsize=(10, 8))
sns.heatmap(subset.corr(), cmap='coolwarm', annot=False)
plt.title("Correlation Heatmap (First 20 Features)")
plt.show()

# Flatten the entire ECG matrix for distribution
ecg_values = df.drop('Target', axis=1).values.flatten().astype(float)

plt.hist(ecg_values, bins=100, color='skyblue', edgecolor='black')
plt.title("Distribution of ECG Signal Amplitudes")
plt.xlabel("Amplitude")
plt.ylabel("Frequency")
plt.grid(True)
plt.show()

subset = df.iloc[:, :10].astype(float)  # first 10 features
subset.columns = [f"ECG_{i}" for i in range(10)]

plt.figure(figsize=(10, 5))
sns.boxplot(data=subset)
plt.title("Boxplot of ECG Signals (First 10 Time Steps)")
plt.xlabel("Feature")
plt.ylabel("Amplitude")
plt.show()

sns.countplot(x='Target', data=df, palette='Set2')
plt.title('Class Distribution')
plt.xticks([0, 1], ['Normal', 'Apnea'])
plt.ylabel('Count')
plt.xlabel('Condition')
plt.show()

labels = ['Normal', 'Apnea']
sizes = df['Target'].value_counts()
plt.figure(figsize=(6,6))
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140, colors=['skyblue', 'salmon'])
plt.title('Class Distribution - Pie Chart')
plt.axis('equal')
plt.show()

# You can change to top 4 numeric columns
selected_features = df.select_dtypes(include=[np.number]).columns[:4].tolist()
sns.pairplot(df[selected_features + ['Target']], hue='Target', palette='husl')
plt.suptitle('Pairwise Feature Relationships', y=1.02)
plt.show()

numerical_cols = df.select_dtypes(include=np.number).columns[:4]
for col in numerical_cols:
    plt.figure()
    sns.histplot(data=df, x=col, hue='Target', kde=True, palette='Set1')
    plt.title(f'Distribution of {col}')
    plt.show()

for col in numerical_cols:
    plt.figure()
    sns.boxplot(x='Target', y=col, data=df, palette='coolwarm')
    plt.title(f'{col} by Class')
    plt.xticks([0, 1], ['Normal', 'Apnea'])
    plt.show()

from math import pi

# Pick a few features for radar
features = df.select_dtypes(include=np.number).columns[:5]
grouped = df.groupby('Target')[features].mean()

# Setup for Radar
labels = features
angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()
angles += angles[:1]  # close the loop

fig = plt.figure(figsize=(8,8))
ax = plt.subplot(111, polar=True)

for i, row in grouped.iterrows():
    values = row.tolist()
    values += values[:1]
    label = 'Apnea' if i == 1 else 'Normal'
    ax.plot(angles, values, label=label)
    ax.fill(angles, values, alpha=0.1)

ax.set_thetagrids(np.degrees(angles[:-1]), labels)
plt.title('Radar Chart of Features by Class')
plt.legend(loc='upper right')
plt.show()

for col in numerical_cols:
    plt.figure()
    sns.violinplot(x='Target', y=col, data=df, palette='Set3', inner='quartile')
    plt.title(f'Violin Plot of {col}')
    plt.xticks([0, 1], ['Normal', 'Apnea'])
    plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import accuracy_score

# Load your CSV
df = pd.read_csv("ecg_sleep_apnea_dataset.csv")  # Change path if needed

# Features and Target
X = df.drop(columns=['Target'])
y = df['Target']

# Convert target to integer by mapping string labels to numerical values
y = y.map({'Normal': 0, 'Sleep Apnea': 1})

# Normalize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Reshape input for CNN (samples, features, channels)
X_reshaped = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)

# One-hot encode the labels
y_cat = to_categorical(y)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_cat, test_size=0.2, random_state=42)

# CNN Model
model = Sequential([
    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_reshaped.shape[1], 1)),
    MaxPooling1D(pool_size=2),
    Dropout(0.3),

    Conv1D(128, kernel_size=3, activation='relu'),
    MaxPooling1D(pool_size=2),
    Dropout(0.3),

    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(2, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

# Predict and evaluate
y_pred_probs = model.predict(X_test)
y_pred = np.argmax(y_pred_probs, axis=1)
y_true = np.argmax(y_test, axis=1)

# Accuracy
acc = accuracy_score(y_true, y_pred)
print("Test Accuracy: {:.2f}%".format(acc * 100))







